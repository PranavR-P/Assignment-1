{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RksWtNuHg9Rb"
      },
      "source": [
        "# Neural Quest Assignment-1\n",
        "*  In this assignment, we will build a classifier for MNIST from scratch using just [NumPy](https://numpy.org/)\n",
        "\n",
        "*  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset contains images of handwritten digits of size 28x28\n",
        "\n",
        "*  The dataset that you are expected to use for training can be found [here](https://drive.google.com/file/d/1DF-OWSP803x34FrvaJ4XeDm_QZUevu32/view?usp=sharing)\n",
        "\n",
        "*   Our model will have 1 hidden layer, like the one below (not our recommendation to use 256 in the hidden layer though, try various values out)\n",
        "\n",
        "**Feel free to redefine any function signatures below, just make sure the final cell remains the same.**\n",
        "\n",
        "<center>\n",
        "<img src=\"https://user-images.githubusercontent.com/81357954/166119893-4ca347b8-b1a4-40b8-9e0a-2e92b5f164ae.png\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyOAG55siwdI"
      },
      "source": [
        "## Import libraries here\n",
        "NumPy, Matplotlib, ...\n",
        "\n",
        "Also remember to initialize the seed for reproducibility of results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iVUsRLxjAb9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(42)  # Setting random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSHNUcJHdkn",
        "outputId": "feacfd52-0e08-4b30-9302-27e0b0ece379"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/train_data.pkl\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Get the current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Join the current directory with the file name or relative file path\n",
        "file_path = os.path.join(current_dir, 'train_data.pkl')\n",
        "\n",
        "# Print the file path\n",
        "print(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaLDC4wN0eQs"
      },
      "source": [
        "## Load *Dataset*\n",
        "Load data from the given pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qOjNSmx0iUn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "ce0acc70-9136-49d5-8134-2c302d128e70"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-534b4db778b4>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/pranavsaireddy/Downloads/train_data.pkl'"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Define the path to your dataset file\n",
        "dataset_path = '/Users/pranavsaireddy/Downloads/train_data.pkl'\n",
        "\n",
        "# Load the dataset\n",
        "with open(dataset_path, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "# Access the data\n",
        "X, y = data['X'], data['y']\n",
        "\n",
        "# Normalize the data\n",
        "X = X / 255.0\n",
        "\n",
        "# Split into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id77Oqc90kTf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "d99aead3-f7e8-466f-9333-5fa1d816b043"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2adad07600f6>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# display a 4x4 grid,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# choose 16 images randomly, display the images as well as corresponding labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# display a 4x4 grid, \n",
        "# choose 16 images randomly, display the images as well as corresponding labels\n",
        "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    idx = np.random.randint(len(X_train))\n",
        "    ax.imshow(X_train[idx].reshape(28, 28), cmap='gray')\n",
        "    ax.set_title(f\"Label: {y_train[idx]}\")\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFYnsPVLmsiW"
      },
      "source": [
        "## Building up parts of our classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAsGtgxUpGh2"
      },
      "source": [
        "**Activation functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Di5Ck47msCQ"
      },
      "outputs": [],
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-q5HJHIocdn"
      },
      "source": [
        "**Notes about the Neural Network** \n",
        "*   Input size is (784,) because 28x28 = 784\n",
        "*   Output size will be 10, each element represeting probability of the image representing that digit\n",
        "*   Size of the hidden layer is a hyperparameter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azTAuS5spFcz"
      },
      "source": [
        "**Initialize the layers weights**\n",
        "\n",
        "Generally, we follow the convention that weights are drawn from a standard normal distribution, while the bias vectors are initialized to zero. But you can try everything out :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38E3_hVPocMm"
      },
      "outputs": [],
      "source": [
        "def init_params(input_dim, hidden_dim, output_dim):\n",
        "    params = {}\n",
        "\n",
        "    params['W1'] = np.random.randn(input_dim, hidden_dim) * 0.01\n",
        "    params['b1'] = np.zeros((1, hidden_dim))\n",
        "\n",
        "    params['W2'] = np.random.randn(hidden_dim, output_dim) * 0.01\n",
        "    params['b2'] = np.zeros((1, output_dim))\n",
        "\n",
        "    return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlX8zy-7pv2n"
      },
      "source": [
        "**Forward Propagation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ8lgrqjjASz"
      },
      "outputs": [],
      "source": [
        "def forward_prop(X, params):\n",
        "    Z1 = np.dot(X, params['W1']) + params['b1']\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "    Z2 = np.dot(A1, params['W2']) + params['b2']\n",
        "    A2 = softmax(Z2)\n",
        "\n",
        "    return A2, {'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asZmbRVvuy5x"
      },
      "source": [
        "**Backward Propagation**\n",
        "\n",
        "\n",
        "You may use stochastic gradient descent or batch gradient descent here. Feel free to use any loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAmrTAlimjUN"
      },
      "outputs": [],
      "source": [
        "def backward_prop(X, y, params, cache):\n",
        "    m = X.shape[0]\n",
        "    dZ2 = cache['A2'] - y\n",
        "    dW2 = np.dot(cache['A1'].T, dZ2) / m\n",
        "    db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
        "    dA1 = np.dot(dZ2, params['W2'].T)\n",
        "    dZ1 = np.multiply(dA1, np.int64(cache['Z1'] > 0))\n",
        "    dW1 = np.dot(X.T, dZ1) / m\n",
        "    db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
        "    return {'dW1': dW1, 'db1': db1, 'dW2': dW2, 'db2': db2}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVDz0IGnvzpe"
      },
      "outputs": [],
      "source": [
        "def cost_func(A2, y):\n",
        "    m = y.shape[0]\n",
        "    loss = -np.sum(np.multiply(y, np.log(A2))) / m\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUlhpcs9ylOX"
      },
      "source": [
        "\n",
        "## Integrate everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDGdT7PVmjRU"
      },
      "outputs": [],
      "source": [
        "def train(X, y, hidden_nodes, epochs=1000, lr=1e-5):\n",
        "    weights = init_params(hidden_nodes)\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        logits, y_pred, layer_0 = forward_propg(X, weights)\n",
        "        weights = backward_propg(weights, X, y, y_pred, layer_0, lr)\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            loss = cost_func(y_pred, y)\n",
        "            print(f\"Epoch {i}: Loss = {loss:.2f}\")\n",
        "    \n",
        "    return weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XBinWpPmjOS"
      },
      "outputs": [],
      "source": [
        "def predict(X, weights):\n",
        "    _, y_pred, _ = forward_propg(X, weights)\n",
        "    return np.argmax(y_pred, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtKSZWw71wc4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGVOZ8yg0VrV"
      },
      "source": [
        "### Save as pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_lvDVwmxmjKX",
        "outputId": "a110014e-c5a6-4492-a00e-0e86abc731d1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4db2a111-32fb-404b-987a-6c58f5e43db8\", \"model_22b0654.pkl\", 814490)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pickle\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "roll_num = \"22b0654\" # enter your ldap\n",
        "hidden_dim = 128 # replace with your own hidden dimension\n",
        "\n",
        "model_dict = {\n",
        "    'z': hidden_dim, # hidden dimension of your model\n",
        "    'layer_0_wt': np.random.randn(784, hidden_dim), # layer 0 weight (784, z)\n",
        "    'layer_0_bias': np.zeros((hidden_dim, 1)), # layer 0 bias (z, 1)\n",
        "    'layer_1_wt': np.random.randn(hidden_dim, 10), # layer 1 weight (z, 10)\n",
        "    'layer_1_bias': np.zeros((10, 1)) # layer 1 bias (10, 1)\n",
        "}\n",
        "\n",
        "assert model_dict['layer_0_wt'].shape == (784, hidden_dim)\n",
        "assert model_dict['layer_0_bias'].shape == (hidden_dim, 1)\n",
        "assert model_dict['layer_1_wt'].shape == (hidden_dim, 10)\n",
        "assert model_dict['layer_1_bias'].shape == (10, 1)\n",
        "\n",
        "with open(f'model_{roll_num}.pkl', 'wb') as f:\n",
        "    pickle.dump(model_dict, f)\n",
        "    files.download(f'model_{roll_num}.pkl') # download the file from the Colab session for submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8PNQmu_Hdkv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9B3NFHeHdkv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}